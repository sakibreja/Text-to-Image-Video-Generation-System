# Text-to-Image-Video-Generation-System

***Tools Used: Python, PyTorch, OpenAI CLIP, Taming Transformers, CUDA, Google Colab, ImageIO, NumPy, PIL, Matplotlib***

*. Developed a generative AI pipeline to synthesize images and videos from text prompts by integrating CLIP (Contrastive Language-Image Pretraining) with Taming Transformers for high-resolution visual generation.

*. Engineered end-to-end workflows for text encoding, latent space optimization, and image synthesis using PyTorch, achieving alignment between textual prompts and generated visuals (e.g., "A Blue Tree in the Forest").

*. Implemented dynamic video generation by interpolating latent vectors, enabling smooth transitions between generated frames and exporting results as MP4 videos.

*. Configured GPU-accelerated environments in Google Colab, optimized model training loops, and resolved dependencies for CUDA, PyTorch Lightning, and VQ-GAN architectures.

*. Utilized debugging tools (e.g., pdb) and performance monitoring (NVIDIA-SMI) to troubleshoot GPU memory usage and model convergence issues.

*. Visualized results using Matplotlib and PIL, ensuring quality control through normalization and augmentation techniques.
